# -*- coding: utf-8 -*-
"""Updated Model Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZL9IqdhAsgoz3f7QPL7DipdMH2KlSz7
"""

# Commented out IPython magic to ensure Python compatibility.
# this mounts your Google Drive to the Colab VM.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# enter the foldername in your Drive where you have saved the unzipped
# workshop folder, e.g. 'acmlab/workshops/week1'
FOLDERNAME = 'acmlab/project/project'
assert FOLDERNAME is not None, "[!] Enter the foldername."

# now that we've mounted your Drive, this ensures that
# the Python interpreter of the Colab VM can load
# python files from within it.
import sys
sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))

# %cd /content/drive/My\ Drive/$FOLDERNAME/

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# Importing the standard ML libraries...
# %load_ext autoreload
# %reload_ext autoreload

import pandas as pd                     # to process our data
import matplotlib.pyplot as plt         # graphing
# from utils import decision_boundary     # for plotting
from sklearn.linear_model import LogisticRegression # our shallow neural network
from PIL import Image


import torch
import numpy as np
import matplotlib.pyplot as plt
import util
import webmercator
import os
from PIL import Image
import json
import torchvision
from torchvision import transforms
from tqdm import tqdm
import random

# Opening JSON file
with open('tile_to_income_annotations.json') as json_file:
    data = json.load(json_file)
  
    # Print the type of data variable
    print("Type:", type(data))

print(data)

testData = {}
trainData = {}
for key in data.keys():
  if (random.randint(0,9) < 6):
    testData[key] = data[key]
  else:
    trainData[key] = data[key]

print(len(testData))
print(len(trainData))

class TrainDataset(torch.utils.data.Dataset):
  def __init__(self, data):
    self.images = []
    self.labels = []
    self.transform = transforms.Compose([transforms.ToTensor()])
    self.transform90 = transforms.Compose([transforms.RandomRotation((90,90)), transforms.ToTensor()])
    self.transform180 = transforms.Compose([transforms.RandomRotation((180,180)), transforms.ToTensor()])
    self.transform270 = transforms.Compose([transforms.RandomRotation((270,270)), transforms.ToTensor()])

    self.transformFlipH = transforms.Compose([transforms.RandomHorizontalFlip(p=1), transforms.ToTensor()])
    self.transformFlipV = transforms.Compose([transforms.RandomVerticalFlip(p=1), transforms.ToTensor()])
    
    for key in tqdm(data):
      image = Image.open("imagery/" + key).convert("RGB")
      
      self.images.append(self.transform(image))
      self.labels.append(float(data[key]))

      self.images.append(self.transform90(image))
      self.labels.append(float(data[key]))

      self.images.append(self.transform180(image))
      self.labels.append(float(data[key]))

      self.images.append(self.transform270(image))
      self.labels.append(float(data[key]))

      self.images.append(self.transformFlipH(image))
      self.labels.append(float(data[key]))

      self.images.append(self.transformFlipV(image))
      self.labels.append(float(data[key]))


  def __len__(self):
    return len(self.images)
  def __getitem__(self, idx):
    return self.images[idx], self.labels[idx]

class TestDataset(torch.utils.data.Dataset):
  def __init__(self, data):
    self.images = []
    self.labels = []
    self.transform = transforms.Compose([transforms.ToTensor()])
    
    for key in tqdm(data):
      image = Image.open("imagery/" + key).convert("RGB")
      
      self.images.append(self.transform(image))
      self.labels.append(float(data[key]))


  def __len__(self):
    return len(self.images)
  def __getitem__(self, idx):
    return self.images[idx], self.labels[idx]

# class ImageDataset(torch.utils.data.Dataset):
#   def __init__(self, data):
#     self.images = []
#     self.labels = []
#     self.transform = transforms.Compose([transforms.ToTensor()])
    
#     for key in tqdm(data):
#       image = Image.open("imagery/" + key).convert("RGB")
      
#       self.images.append(image)
#       self.labels.append(float(data[key]))


#   def __len__(self):
#     return len(self.images)
#   def __getitem__(self, idx):
#     return self.transform(self.images[idx]), self.labels[idx]

trainset = torch.load("trainset.pt")
print(trainset.__len__())

testset = torch.load("testset.pt")
print(testset.__len__())

trainset = TrainDataset(trainData)
testset = TestDataset(testData)

print(trainset.__len__())
print(testset.__len__())

torch.save(trainset, "trainset.pt")
torch.save(testset, "testset.pt")

figure = plt.figure(figsize=(15, 10))
trans = transforms.ToPILImage()
plt.imshow(trans(trainset.__getitem__(5)[0]))

print(trainset.__len__())
print(testset.__len__())
print(type(trainset))

batch_size = 64
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)

dataiter = iter(trainloader)
images, labels = dataiter.next()
print(images.shape)
print(labels.shape)

# Display the images
figure = plt.figure(figsize=(15, 10))
num_rows = 8
num_cols = 8
for idx in range(batch_size):
  plt.subplot(num_rows, num_cols, idx + 1) # subplot indices begin at 1, not 0
  plt.axis('off')
  trans = transforms.ToPILImage()
  plt.imshow(trans(images[idx]))

import torch.nn as nn
import torch.nn.functional as F

class ConvolutionalNeuralNet(nn.Module):
  def __init__(self):
    super(ConvolutionalNeuralNet, self).__init__()
    self.conv1 = nn.Conv2d(3, 10, 5)
    self.pool = nn.MaxPool2d(2, 2)
    self.conv2 = nn.Conv2d(10, 20, 5)
    self.conv3 = nn.Conv2d(20, 40, 5)
    self.fc1 = nn.Linear(31360, 200)
    self.fc2 = nn.Linear(200, 1)

  def forward(self, x):
    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = self.pool(F.relu(self.conv3(x)))
    x = x.view(x.shape[0], -1)
    x = F.relu(self.fc1(x))
    x = self.fc2(x)
    return x

# take advantage of GPU if available
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

cnn_model = torch.load("model.pt")

# fill these in!
cnn_model = ConvolutionalNeuralNet().to(device = device) # Don't forget to add .to(device=device)
criterion = torch.nn.MSELoss(reduction="mean")
optimizer = torch.optim.Adam(cnn_model.parameters(), lr = 0.001) 
  

for epoch in range(10):
  epoch_loss = 0
  for batch_idx, (images, labels) in enumerate(trainloader):
    images = images.to(device=device)
    labels = labels.to(device=device).float().view((len(labels),1)) # Put the labels on GPU as well
    
    # Fill in the rest of the training loop
    optimizer.zero_grad()                 # resets the information from last time
    pred_y = cnn_model(images)            # calculates the predictions
    loss = criterion(pred_y, labels)     # calculates the loss
    loss.backward()                       # gradient descent, part 1
    torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), 150)
    optimizer.step()                      # gradient descent, part 2

    epoch_loss += loss.item() / labels.shape[0]
    if batch_idx % 100 == 0:
      print(f"Epoch {epoch}, batch {batch_idx}: {loss}")

  print(f"Epoch {epoch}: {epoch_loss}")

import math
average_absolute_error = 0
total = 0
otherTotal = 0
with torch.no_grad():
  for images, labels in testloader:
    outputs = cnn_model(images.to(device=device))
    predicted = outputs.data
    predicted = predicted.cpu()   # Move to cpu to be compared with labels, which are on cpu
    for i in range(predicted.shape[0]):
      average_absolute_error += abs(predicted[i][0] - labels[i])
      print(abs(predicted[i][0] - labels[i]))
      if(abs(predicted[i][0] - labels[i]) > 100):
        print(labels[i])
        print(predicted[i][0])
        
      total += 1;

    # print(differences.shape)
    # for i in range(differences.shape[0]):
    #   for j in range(differences.shape[1]):
    #     average_absolute_error += differences[i][j]
    #     otherTotal += 1
# print(otherTotal)
print(f'average_absolute_error of the network on the {total} test images: {average_absolute_error / total}')

import math
average_absolute_error = 0
total = 0
otherTotal = 0
with torch.no_grad():
  for images, labels in trainloader:
    outputs = cnn_model(images.to(device=device))
    predicted = outputs.data
    predicted = predicted.cpu()   # Move to cpu to be compared with labels, which are on cpu
    for i in range(predicted.shape[0]):
      average_absolute_error += abs(predicted[i][0] - labels[i])
      print(abs(predicted[i][0] - labels[i]))
      total += 1;

    # print(differences.shape)
    # for i in range(differences.shape[0]):
    #   for j in range(differences.shape[1]):
    #     average_absolute_error += differences[i][j]
    #     otherTotal += 1
# print(otherTotal)
print(f'average_absolute_error of the network on the {total} test images: {average_absolute_error / total}')

torch.save(cnn_model, "model.pt")

